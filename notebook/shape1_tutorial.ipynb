{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91826ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import socket\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from util import adjust_learning_rate, accuracy, AverageMeter\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5f6326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd3fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "parser.add_argument('--eval_freq', type=int, default=10, help='meta-eval frequency')\n",
    "parser.add_argument('--print_freq', type=int, default=100, help='print frequency')\n",
    "parser.add_argument('--tb_freq', type=int, default=500, help='tb frequency')\n",
    "parser.add_argument('--save_freq', type=int, default=10, help='save frequency')\n",
    "parser.add_argument('--batch_size', type=int, default=4, help='batch_size')\n",
    "parser.add_argument('--num_workers', type=int, default=8, help='num of workers to use')\n",
    "parser.add_argument('--epochs', type=int, default=200, help='number of training epochs')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='learning rate')\n",
    "parser.add_argument('--lr_decay_epochs', type=str, default='60,80', help='where to decay lr, can be a list')\n",
    "parser.add_argument('--lr_decay_rate', type=float, default=0.1, help='decay rate for learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4, help='weight decay')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--adam', action='store_true', help='use adam optimizer')\n",
    "\n",
    "# dataset\n",
    "parser.add_argument('--model', type=str, default='resnet50')\n",
    "\n",
    "# cosine annealing\n",
    "parser.add_argument('--cosine', action='store_true', help='using cosine annealing')\n",
    "\n",
    "# specify folder\n",
    "parser.add_argument('--model_path', type=str, default='', help='path to save model')\n",
    "parser.add_argument('--tb_path', type=str, default='', help='path to tensorboard')\n",
    "parser.add_argument('--data_root', type=str, default='', help='path to data root')\n",
    "\n",
    "opt = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550f5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = opt.lr_decay_epochs.split(',')\n",
    "opt.lr_decay_epochs = list([])\n",
    "for it in iterations:\n",
    "    opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "opt.n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b72475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datasets\n",
    "train_transforms_option = transforms.Compose([\n",
    "                    transforms.Resize((32, 32)),\n",
    "                    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761])\n",
    "                ])\n",
    "train_datasets = torchvision.datasets.ImageFolder(root=\"../dataset/shape_style1_set/train\", transform = train_transforms_option)\n",
    "train_loader = torch.utils.data.DataLoader(train_datasets, batch_size = 256, shuffle=True, num_workers = 4)\n",
    "\n",
    "\n",
    "test_transforms_option = transforms.Compose([\n",
    "                    transforms.Resize((32, 32)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761])\n",
    "                ])\n",
    "test_datasets = torchvision.datasets.ImageFolder(root=\"../dataset/shape_style1_set/test\", transform = test_transforms_option)\n",
    "test_loader = torch.utils.data.DataLoader(test_datasets, batch_size = 256, shuffle=False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00c2f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use resnet50\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "n_class = 10 \n",
    "print(f'We use {opt.model}')\n",
    "model = resnet50(pretrained = False)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a1c9f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "if opt.adam:\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=opt.learning_rate,weight_decay=0.0005)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(),lr=opt.learning_rate,momentum=opt.momentum,weight_decay=opt.weight_decay)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if opt.n_gpu > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b99ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cosine annealing scheduler\n",
    "if opt.cosine:\n",
    "    eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, opt.epochs, eta_min, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de27f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77dcf76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, model, criterion, optimizer, opt):\n",
    "    \"\"\"One epoch training\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc1 = AverageMeter()\n",
    "    f1_1 = AverageMeter()\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, (input, target) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input = input.float()\n",
    "        if torch.cuda.is_available():\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        # ===================forward=====================\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        acc = accuracy(output, target)\n",
    "        pred = output.argmax(dim=1) # .view(output.shape)\n",
    "\n",
    "        f1 = f1_score(target.cpu().detach().numpy(), pred.cpu().detach().numpy(), average = 'micro')\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        acc1.update(acc.item(), input.size(0))\n",
    "        f1_1.update(f1.item(), input.size(0))\n",
    "\n",
    "        # ===================backward=====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ===================meters=====================\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # tensorboard logger\n",
    "        pass\n",
    "\n",
    "        # print info\n",
    "        if idx % opt.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'F1@1 {f1.val: 3f} ({f1.avg:3f})\\t'.format(\n",
    "                   epoch, idx, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=acc1, f1 = f1_1))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    print(' * Acc@1 {top1.avg:.3f} F1@1 {f1.avg:.3f}'.format(top1=acc1, f1=f1_1))\n",
    "\n",
    "    return acc1.avg, losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b7a54a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, opt):\n",
    "    \"\"\"One epoch validation\"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc1 = AverageMeter()\n",
    "    f1_1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (input, target) in enumerate(val_loader):\n",
    "\n",
    "            input = input.float()\n",
    "            if torch.cuda.is_available():\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            pred = output.argmax(dim=1) # .view(output.shape)\n",
    "            f1 = f1_score(target.cpu().detach().numpy(), pred.cpu().detach().numpy(), average = 'micro')\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(output, target)\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            acc1.update(acc, input.size(0))\n",
    "            f1_1.update(f1, input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if idx % opt.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'F1@1 {f1.val:.3f} ({f1.avg:.3f})'.format(\n",
    "                       idx, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                       top1=acc1, f1=f1_1))\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f}'\n",
    "              .format(top1=acc1))\n",
    "\n",
    "    return acc1.avg, losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b70c87-b682-48db-ab36-c6e801ef8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제대로 돌아가는 것까지 확인완료\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1, opt.epochs + 1):\n",
    "    if opt.cosine:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        adjust_learning_rate(epoch, opt, optimizer)\n",
    "    print(\"==> training...\")\n",
    "\n",
    "    time1 = time.time()\n",
    "    train_acc, train_loss = train(epoch, train_loader, model, criterion, optimizer, opt)\n",
    "    time2 = time.time()\n",
    "    print('epoch {}, total time {:.2f}'.format(epoch, time2 - time1))\n",
    "\n",
    "    print(f'[Epoch{epoch}]train_acc', train_acc)\n",
    "    print('train_loss', train_loss)\n",
    "\n",
    "    test_acc, test_loss = validate(test_loader, model, criterion, opt)\n",
    "\n",
    "    print(f'[epoch {epoch}] test_acc : {test_acc}')\n",
    "    print(f'[epoch {epoch}] test_loss : {test_loss}')\n",
    "\n",
    "    # regular saving\n",
    "    if best_acc < test_acc :\n",
    "        best_acc = test_acc\n",
    "        print('==> Saving...')\n",
    "        save_file = os.path.join('./checkpoint/best.pth'.format(epoch=epoch))\n",
    "        torch.save(model.state_dict(), save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 일단 제대로 돌아가는지 확인해보고, 스크립트로 만들어두기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, opt):\n",
    "    \"\"\"One epoch validation\"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc1 = AverageMeter()\n",
    "    f1_1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (input, target) in enumerate(val_loader):\n",
    "\n",
    "            input = input.float()\n",
    "            if torch.cuda.is_available():\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            pred = output.argmax(dim=1) # .view(output.shape)\n",
    "            f1 = f1_score(target.cpu().detach().numpy(), pred.cpu().detach().numpy(), average = 'micro')\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(output, target)\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            acc1.update(acc, input.size(0))\n",
    "            f1_1.update(f1, input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if idx % opt.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'F1@1 {f1.val:.3f} ({f1.avg:.3f})'.format(\n",
    "                       idx, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                       top1=acc1, f1=f1_1))\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f}'\n",
    "              .format(top1=acc1))\n",
    "\n",
    "    return acc1.avg, losses.avg, f1_1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test phase\n",
    "for epoch in range(1, opt.epochs + 1):\n",
    "    print(\"==> Start eval...\")\n",
    "\n",
    "    test_acc, test_loss, test_f1 = test(test_loader, model, criterion, opt)\n",
    "\n",
    "    print(f'[epoch {epoch}] test_acc : {test_acc}')\n",
    "    print(f'[epoch {epoch}] test_loss : {test_loss}')\n",
    "    print(f'[epoch {epoch}] test_f1 : {test_f1}')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m68"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
