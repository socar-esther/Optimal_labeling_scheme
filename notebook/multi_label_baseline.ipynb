{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b099153-5f89-4dbb-a390-4ff668604958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu111\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import socket\n",
    "import time\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from util import adjust_learning_rate, accuracy, AverageMeter,accuracy_top_k\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.metrics import f1_score, accuracy_score, top_k_accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c91313-14ed-442e-be9e-cd1c9d957302",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "parser.add_argument('--eval_freq', type=int, default=10, help='meta-eval frequency')\n",
    "parser.add_argument('--print_freq', type=int, default=100, help='print frequency')\n",
    "parser.add_argument('--tb_freq', type=int, default=500, help='tb frequency')\n",
    "parser.add_argument('--save_freq', type=int, default=10, help='save frequency')\n",
    "parser.add_argument('--batch_size', type=int, default=4, help='batch_size')\n",
    "parser.add_argument('--num_workers', type=int, default=8, help='num of workers to use')\n",
    "parser.add_argument('--epochs', type=int, default=200, help='number of training epochs')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='learning rate')\n",
    "parser.add_argument('--lr_decay_epochs', type=str, default='60,80', help='where to decay lr, can be a list')\n",
    "parser.add_argument('--lr_decay_rate', type=float, default=0.1, help='decay rate for learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4, help='weight decay')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--adam', action='store_true', help='use adam optimizer')\n",
    "\n",
    "# dataset\n",
    "parser.add_argument('--model', type=str, default='resnet50')\n",
    "\n",
    "# cosine annealing\n",
    "parser.add_argument('--cosine', action='store_true', help='using cosine annealing')\n",
    "\n",
    "# specify folder\n",
    "parser.add_argument('--model_path', type=str, default='', help='path to save model')\n",
    "parser.add_argument('--tb_path', type=str, default='', help='path to tensorboard')\n",
    "parser.add_argument('--data_root', type=str, default='', help='path to data root')\n",
    "\n",
    "opt = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60ad8371-ccd0-4195-abac-f953ab37ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = opt.lr_decay_epochs.split(',')\n",
    "opt.lr_decay_epochs = list([])\n",
    "for it in iterations:\n",
    "    opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "opt.n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74643c76-3b22-49d2-ab25-561852140994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 기존에 있는 것들 -> csv 형태로 바꾸기\n",
    "train_path = '../../dataset/ours_style2_set/train'\n",
    "test_path = '../../dataset/ours_style2_set/test'\n",
    "result_dict = {\n",
    "    \"img_path\" : [],\n",
    "    \n",
    "    \"airplane\" : [], \n",
    "    \"automobile\" : [],\n",
    "    \"bird\" : [],\n",
    "    \"cat\" : [],\n",
    "    \"deer\" : [],\n",
    "    \"dog\" : [],\n",
    "    \"frog\" : [],\n",
    "    \"horse\" : [],\n",
    "    \"ship\": [],\n",
    "    \"truck\" : [],\n",
    "    \"original\" : [], \n",
    "    \"stylized\" : []\n",
    "}\n",
    "\n",
    "# 총 클래스는 shape(10개) + original + style1 ; 총 12개로 두면 될듯\n",
    "for class_nm in os.listdir(train_path) :\n",
    "    if '.ipy' in class_nm :\n",
    "        continue\n",
    "    else :\n",
    "        # 각 이미지 path를 설정\n",
    "        for file_nm in os.listdir(os.path.join(train_path, class_nm) ) : \n",
    "            img_path = os.path.join(train_path, class_nm, file_nm)\n",
    "            \n",
    "            # file path 먼저 채우고\n",
    "            result_dict['img_path'].append(img_path)\n",
    "            \n",
    "            # texture부분 채우고\n",
    "            if 'style2' in class_nm :\n",
    "                result_dict['stylized'].append(1)\n",
    "                result_dict['original'].append(0)\n",
    "            else :\n",
    "                result_dict['original'].append(1)\n",
    "                result_dict['stylized'].append(0)\n",
    "            \n",
    "            # shape부분 채운다\n",
    "            shape_list = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "            \n",
    "            for shape_nm in shape_list :\n",
    "                if shape_nm in class_nm :\n",
    "                    result_dict[shape_nm].append(1)\n",
    "                    \n",
    "                    # shape_nm 이외에 다른 shape들에는 0 값 넣음\n",
    "                    for shape_nm_2 in shape_list :\n",
    "                        if shape_nm_2 != shape_nm :\n",
    "                            result_dict[shape_nm_2].append(0)\n",
    "                    break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89f7e3b0-e273-45db-8972-cc89865b2e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test에 대해서도 생성\n",
    "result_test_dict = {\n",
    "    \"img_path\" : [],\n",
    "    \n",
    "    \"airplane\" : [], \n",
    "    \"automobile\" : [],\n",
    "    \"bird\" : [],\n",
    "    \"cat\" : [],\n",
    "    \"deer\" : [],\n",
    "    \"dog\" : [],\n",
    "    \"frog\" : [],\n",
    "    \"horse\" : [],\n",
    "    \"ship\": [],\n",
    "    \"truck\" : [],\n",
    "    \"original\" : [], \n",
    "    \"stylized\" : []\n",
    "}\n",
    "\n",
    "\n",
    "for class_nm in os.listdir(test_path) :\n",
    "    if '.ipy' in class_nm :\n",
    "        continue\n",
    "    else :\n",
    "        # 각 이미지 path를 설정\n",
    "        for file_nm in os.listdir(os.path.join(test_path, class_nm) ) : \n",
    "            img_path = os.path.join(test_path, class_nm, file_nm)\n",
    "            \n",
    "            # file path 먼저 채우고\n",
    "            result_test_dict['img_path'].append(img_path)\n",
    "            \n",
    "            # texture부분 채우고\n",
    "            if 'style2' in class_nm :\n",
    "                result_test_dict['stylized'].append(1)\n",
    "                result_test_dict['original'].append(0)\n",
    "            else :\n",
    "                result_test_dict['original'].append(1)\n",
    "                result_test_dict['stylized'].append(0)\n",
    "            \n",
    "            # shape부분 채운다\n",
    "            shape_list = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "            \n",
    "            for shape_nm in shape_list :\n",
    "                if shape_nm in class_nm :\n",
    "                    result_test_dict[shape_nm].append(1)\n",
    "                    \n",
    "                    # shape_nm 이외에 다른 shape들에는 0 값 넣음\n",
    "                    for shape_nm_2 in shape_list :\n",
    "                        if shape_nm_2 != shape_nm :\n",
    "                            result_test_dict[shape_nm_2].append(0)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c690f2f-2f86-4efc-ae42-23e59cc89310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96821\n",
      "96821\n",
      "96821\n",
      "96821\n",
      "96821\n",
      "96821\n",
      "96821\n",
      "96821\n",
      "96821\n",
      "96821\n",
      "96821\n",
      "96821\n",
      "96821\n",
      "\n",
      "16000\n",
      "16000\n",
      "16000\n",
      "16000\n",
      "16000\n",
      "16000\n",
      "16000\n",
      "16000\n",
      "16000\n",
      "16000\n",
      "16000\n",
      "16000\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "for key, value_list in result_dict.items() :\n",
    "    print(len(value_list))\n",
    "    \n",
    "print()\n",
    "for key, value_list in result_test_dict.items() :\n",
    "    print(len(value_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c6eb87d-0f28-4602-b8c7-6a1ae770039c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "      <th>original</th>\n",
       "      <th>stylized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>../../dataset/ours_style2_set/test/truck/truck...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>../../dataset/ours_style2_set/test/truck/truck...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>../../dataset/ours_style2_set/test/truck/truck...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>../../dataset/ours_style2_set/test/truck/truck...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>../../dataset/ours_style2_set/test/truck/truck...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                img_path  airplane  \\\n",
       "15995  ../../dataset/ours_style2_set/test/truck/truck...         0   \n",
       "15996  ../../dataset/ours_style2_set/test/truck/truck...         0   \n",
       "15997  ../../dataset/ours_style2_set/test/truck/truck...         0   \n",
       "15998  ../../dataset/ours_style2_set/test/truck/truck...         0   \n",
       "15999  ../../dataset/ours_style2_set/test/truck/truck...         0   \n",
       "\n",
       "       automobile  bird  cat  deer  dog  frog  horse  ship  truck  original  \\\n",
       "15995           0     0    0     0    0     0      0     0      1         1   \n",
       "15996           0     0    0     0    0     0      0     0      1         1   \n",
       "15997           0     0    0     0    0     0      0     0      1         1   \n",
       "15998           0     0    0     0    0     0      0     0      1         1   \n",
       "15999           0     0    0     0    0     0      0     0      1         1   \n",
       "\n",
       "       stylized  \n",
       "15995         0  \n",
       "15996         0  \n",
       "15997         0  \n",
       "15998         0  \n",
       "15999         0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv로 생성하고 저장해두기\n",
    "train_csv = pd.DataFrame(result_dict)\n",
    "train_csv.head()\n",
    "\n",
    "test_csv = pd.DataFrame(result_test_dict)\n",
    "test_csv.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14435d45-027d-47fb-946f-6fac8b2a1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파잎 저장\n",
    "train_csv.to_csv('../../dataset/ours_style2_set/train.csv', index = False)\n",
    "test_csv.to_csv('../../dataset/ours_style2_set/test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2bb81-f3ad-4fd5-83a0-70fc2e09bc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d716e15d-69e6-43cf-867f-4ee481cef74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabel_Styleized_CIFAR10(Dataset):\n",
    "    def __init__(self, image_ids, transforms) :\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.labels = {}\n",
    "        with open(image_ids, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for row in reader:\n",
    "                self.labels[row[0]] = list(map(int, row[1:]))\n",
    "\n",
    "        self.image_ids = list(self.labels.keys())\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.image_ids[index]\n",
    "        image = Image.open(\n",
    "            os.path.join(f'{str(image_id)}')).convert('RGB')\n",
    "        target = np.array(self.labels.get(image_id)).astype(np.float32)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4348efd-10e4-4c33-a678-9325d04e346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms_option = transforms.Compose([\n",
    "                    transforms.Resize((32, 32)),\n",
    "                    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761])\n",
    "                ])\n",
    "\n",
    "test_transforms_option = transforms.Compose([\n",
    "                    transforms.Resize((32, 32)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761])\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba90e893-20ff-4196-bd83-70ed219eca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MultiLabel_Styleized_CIFAR10('../../dataset/ours_style2_set/train.csv', train_transforms_option)\n",
    "testset = MultiLabel_Styleized_CIFAR10('../../dataset/ours_style2_set/test.csv', test_transforms_option)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=256, num_workers=8)\n",
    "test_loader = DataLoader(testset, batch_size=32, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c1a830f-5fab-4c13-8891-58453a071794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use resnet50\n"
     ]
    }
   ],
   "source": [
    "# model load\n",
    "print(f'We use {opt.model}')\n",
    "model = resnet50(pretrained = False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b3e221-70a5-42b7-8fd2-639cad19f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "if opt.adam:\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=opt.learning_rate,weight_decay=0.0005)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(),lr=opt.learning_rate,momentum=opt.momentum,weight_decay=opt.weight_decay)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if opt.n_gpu > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "305c7ac5-1b1e-485e-b1c4-4242e5384af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cosine annealing scheduler\n",
    "if opt.cosine:\n",
    "    eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, opt.epochs, eta_min, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f68392a-b697-4380-b997-7159ed5dee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fffcbc0-768a-4be8-97fa-0b92d3902a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, model, criterion, optimizer, opt):\n",
    "    \"\"\"One epoch training\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, (input, target) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input = input.float()\n",
    "        if torch.cuda.is_available():\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        # ===================forward=====================\n",
    "        output = model(input)\n",
    "        output = torch.sigmoid(output)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        losses.update(loss.item(), input.size(0))\n",
    "\n",
    "        # ===================backward=====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ===================meters=====================\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # tensorboard logger\n",
    "        pass\n",
    "\n",
    "        # print info\n",
    "        if idx % opt.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                   epoch, idx, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "645a892c-58f8-4909-94e1-5fa39af38711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, opt):\n",
    "    \"\"\"One epoch validation\"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (input, target) in enumerate(val_loader):\n",
    "\n",
    "            input = input.float()\n",
    "            if torch.cuda.is_available():\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            output = torch.sigmoid(output)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if idx % opt.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                       idx, len(val_loader), batch_time=batch_time, loss=losses,))\n",
    "\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82924dda-cdf1-442f-9817-eb771dad082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3c3b62-829f-4c8b-9a64-d166371e18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제대로 돌아가는 것까지 확인완료\n",
    "best_acc = 0.0\n",
    "best_loss = 1000.0\n",
    "\n",
    "for epoch in range(1, opt.epochs + 1):\n",
    "    if opt.cosine:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        adjust_learning_rate(epoch, opt, optimizer)\n",
    "    print(\"==> training...\")\n",
    "\n",
    "    time1 = time.time()\n",
    "    train_loss = train(epoch, train_loader, model, criterion, optimizer, opt)\n",
    "    time2 = time.time()\n",
    "    print('epoch {}, total time {:.2f}'.format(epoch, time2 - time1))\n",
    "\n",
    "    print(f'[Epoch{epoch}] train_loss', train_loss)\n",
    "\n",
    "    test_loss = validate(test_loader, model, criterion, opt)\n",
    "\n",
    "    print(f'[epoch {epoch}] test_loss : {test_loss}')\n",
    "\n",
    "    # regular saving\n",
    "    if best_loss > test_loss :\n",
    "        best_loss = test_loss\n",
    "        print('==> Saving...')\n",
    "        save_file = os.path.join('../checkpoint_multi/ours_style1_best.pth'.format(epoch=epoch))\n",
    "        torch.save(model.state_dict(), save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3bcb06-211a-4c5d-a278-008eb5ce36e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d1c41a7-472f-4dec-b5e8-7c44d16a9248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50(pretrained = False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 12) # num_classes\n",
    "model.load_state_dict(torch.load(os.path.join('../checkpoint_multi/ours_style2_best.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0516477-5840-4db1-9322-aed1ccf458cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    correct_count = 0.0\n",
    "    \n",
    "    for i in range(len(targets)) :\n",
    "        if predictions[i] == targets[i] :\n",
    "            correct_count += 1.0\n",
    "            \n",
    "    return correct_count / len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf55451-8609-4eda-8770-68db9a6bfd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= model.cuda()\n",
    "model.eval()\n",
    "\n",
    "losses = AverageMeter()\n",
    "acc1 = AverageMeter()\n",
    "f1_1 = AverageMeter()\n",
    "\n",
    "with torch.no_grad() : \n",
    "    for idx, (input, target) in enumerate(test_loader):\n",
    "        input = input.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "        target_list = list()\n",
    "        for i in range(len(target)) :\n",
    "            target_list.append(target[i].cpu().detach().numpy()[:10])\n",
    "\n",
    "        target_arr = torch.tensor(np.array(target_list))\n",
    "\n",
    "\n",
    "        # get all the index positions where value == 1\n",
    "        target_indices = [i for i in range(len(target_arr[0])) if target_arr[0][i] == 1]\n",
    "\n",
    "        # get the predictions by passing the image through the model\n",
    "        outputs = model(input)\n",
    "        outputs_list = list()\n",
    "        for i in range(len(outputs)) :\n",
    "            outputs_list.append(outputs[i].cpu().detach().numpy()[:10])\n",
    "\n",
    "        outputs_arr = np.array(outputs_list)\n",
    "\n",
    "        outputs = torch.sigmoid(torch.tensor(outputs_arr))\n",
    "        outputs = outputs.detach().cpu()\n",
    "        \n",
    "        pred = outputs.argmax(dim=1)\n",
    "        targets = target_arr.argmax(dim=1)\n",
    "    \n",
    "\n",
    "        #f1 = f1_score(target_arr.cpu().detach().numpy(), pred.cpu().detach().numpy(), average = 'weighted')\n",
    "        acc = accuracy(outputs, targets.cpu().detach().numpy())\n",
    "        \n",
    "        acc1.update(acc, input.size(0))\n",
    "        #f1_1.update(f1, input.size(0))\n",
    "        \n",
    "\n",
    "        if idx % opt.print_freq == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                    'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                    #'F1@1 {f1.val:.3f} ({f1.avg:.3f})'\n",
    "                      .format(\n",
    "                       idx, len(test_loader),\n",
    "                       top1=acc1))#, f1=f1_1))\n",
    "\n",
    "print('Test Accuracy : ', acc1.avg)\n",
    "# print('Test F1-score : ', f1_1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c26c2a5c-2aec-4fa5-ac45-9218e06ae97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = outputs.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5b905-4e29-42a5-a8e2-c401208ab984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
