{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d550bfc-8682-42bb-822a-cf5835df0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import socket\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from util import adjust_learning_rate, accuracy, AverageMeter\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9a5169-6ce1-4a10-8c38-8bb58f8e7365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu111\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee3811a-09d6-4041-92f4-60d5a4de2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "parser.add_argument('--eval_freq', type=int, default=10, help='meta-eval frequency')\n",
    "parser.add_argument('--print_freq', type=int, default=100, help='print frequency')\n",
    "parser.add_argument('--tb_freq', type=int, default=500, help='tb frequency')\n",
    "parser.add_argument('--save_freq', type=int, default=10, help='save frequency')\n",
    "parser.add_argument('--batch_size', type=int, default=4, help='batch_size')\n",
    "parser.add_argument('--num_workers', type=int, default=8, help='num of workers to use')\n",
    "parser.add_argument('--epochs', type=int, default=200, help='number of training epochs')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='learning rate')\n",
    "parser.add_argument('--lr_decay_epochs', type=str, default='60,80', help='where to decay lr, can be a list')\n",
    "parser.add_argument('--lr_decay_rate', type=float, default=0.1, help='decay rate for learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4, help='weight decay')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--adam', action='store_true', help='use adam optimizer')\n",
    "\n",
    "# dataset\n",
    "parser.add_argument('--model', type=str, default='resnet50')\n",
    "\n",
    "# cosine annealing\n",
    "parser.add_argument('--cosine', action='store_true', help='using cosine annealing')\n",
    "\n",
    "# specify folder\n",
    "parser.add_argument('--model_path', type=str, default='', help='path to save model')\n",
    "parser.add_argument('--tb_path', type=str, default='', help='path to tensorboard')\n",
    "parser.add_argument('--data_root', type=str, default='', help='path to data root')\n",
    "\n",
    "opt = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe75659-ac73-40f7-b57f-5606eea12d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = opt.lr_decay_epochs.split(',')\n",
    "opt.lr_decay_epochs = list([])\n",
    "for it in iterations:\n",
    "    opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "opt.n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d28d0b5-54d3-4f35-a02f-3546558d207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datasets\n",
    "train_transforms_option = transforms.Compose([\n",
    "                    transforms.Resize((32, 32)),\n",
    "                    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761])\n",
    "                ])\n",
    "train_datasets = torchvision.datasets.ImageFolder(root=\"../../dataset/cifar100/train\", transform = train_transforms_option)\n",
    "train_loader = torch.utils.data.DataLoader(train_datasets, batch_size = 256, shuffle=True, num_workers = 4)\n",
    "\n",
    "\n",
    "test_transforms_option = transforms.Compose([\n",
    "                    transforms.Resize((32, 32)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761])\n",
    "                ])\n",
    "test_datasets = torchvision.datasets.ImageFolder(root=\"../../dataset/cifar100/test\", transform = test_transforms_option)\n",
    "test_loader = torch.utils.data.DataLoader(test_datasets, batch_size = 256, shuffle=False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72378e-e037-4590-ae28-75bb0b503a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "n_cls = 100 # target에서 쓰는 class 수를 의미함\n",
    "source_type = 'ours' #choice = ['random', 'shape', 'texture', 'ours']\n",
    "\n",
    "if source_type == 'random' :\n",
    "    print(f'We use {opt.model}')\n",
    "    model = resnet50(pretrained = False)\n",
    "    \n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, n_cls)\n",
    "\n",
    "elif source_type == 'shape' :\n",
    "    opt.n_class = 10\n",
    "    print(f'We use {opt.model}')\n",
    "    model = resnet50(pretrained = False)\n",
    "    \n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, opt.n_class)\n",
    "\n",
    "    model.load_state_dict(torch.load('../checkpoint_0302/shape_style1_best.pth'))\n",
    "    \n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, n_cls)\n",
    "    \n",
    "elif source_type == 'texture' :\n",
    "    opt.n_class = 2\n",
    "    print(f'We use {opt.model}')\n",
    "    model = resnet50(pretrained = False)\n",
    "    \n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, opt.n_class)\n",
    "\n",
    "    model.load_state_dict(torch.load('../checkpoint_0302/texture_style1_best.pth'))\n",
    "    \n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, n_cls)\n",
    "\n",
    "elif source_type == 'ours' :\n",
    "    opt.n_class = 20\n",
    "    print(f'We use {opt.model}')\n",
    "    model = resnet50(pretrained = False)\n",
    "    \n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, opt.n_class)\n",
    "\n",
    "    model.load_state_dict(torch.load('../checkpoint_0302/ours_style1_best.pth'))\n",
    "    \n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, n_cls)\n",
    "\n",
    "else :\n",
    "    raise NotImplementedError(f'{source_type} is not implemented ..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc9f0599-f18e-41ac-89ef-8ddf1762edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "if opt.adam:\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=opt.learning_rate,weight_decay=0.0005)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(),lr=opt.learning_rate,momentum=opt.momentum,weight_decay=opt.weight_decay)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if opt.n_gpu > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9afb881-2e77-4df3-aa66-963022b5a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cosine annealing scheduler\n",
    "if opt.cosine:\n",
    "    eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, opt.epochs, eta_min, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecba32b0-f976-49dc-8c2d-a5bda42a4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd0f027c-68ab-40b3-a26f-67c705442db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, model, criterion, optimizer, opt):\n",
    "    \"\"\"One epoch training\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc1 = AverageMeter()\n",
    "    f1_1 = AverageMeter()\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, (input, target) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input = input.float()\n",
    "        if torch.cuda.is_available():\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        # ===================forward=====================\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        acc = accuracy(output, target)\n",
    "        pred = output.argmax(dim=1) # .view(output.shape)\n",
    "\n",
    "        f1 = f1_score(target.cpu().detach().numpy(), pred.cpu().detach().numpy(), average = 'micro')\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        acc1.update(acc.item(), input.size(0))\n",
    "        f1_1.update(f1.item(), input.size(0))\n",
    "\n",
    "        # ===================backward=====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ===================meters=====================\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # tensorboard logger\n",
    "        pass\n",
    "\n",
    "        # print info\n",
    "        if idx % opt.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'F1@1 {f1.val: 3f} ({f1.avg:3f})\\t'.format(\n",
    "                   epoch, idx, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=acc1, f1 = f1_1))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    print(' * Acc@1 {top1.avg:.3f} F1@1 {f1.avg:.3f}'.format(top1=acc1, f1=f1_1))\n",
    "\n",
    "    return acc1.avg, losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80af2cce-4534-4363-b23c-be248d6f0457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, opt):\n",
    "    \"\"\"One epoch validation\"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc1 = AverageMeter()\n",
    "    f1_1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, (input, target) in enumerate(val_loader):\n",
    "\n",
    "            input = input.float()\n",
    "            if torch.cuda.is_available():\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            pred = output.argmax(dim=1) # .view(output.shape)\n",
    "            f1 = f1_score(target.cpu().detach().numpy(), pred.cpu().detach().numpy(), average = 'micro')\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(output, target)\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            acc1.update(acc, input.size(0))\n",
    "            f1_1.update(f1, input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if idx % opt.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'F1@1 {f1.val:.3f} ({f1.avg:.3f})'.format(\n",
    "                       idx, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                       top1=acc1, f1=f1_1))\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f}'\n",
    "              .format(top1=acc1))\n",
    "\n",
    "    return acc1.avg, losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6039fb7-ecd3-4980-9058-362dd2f62375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제대로 돌아가는 것까지 확인완료\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1, opt.epochs + 1):\n",
    "    if opt.cosine:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        adjust_learning_rate(epoch, opt, optimizer)\n",
    "    print(\"==> training...\")\n",
    "\n",
    "    time1 = time.time()\n",
    "    train_acc, train_loss = train(epoch, train_loader, model, criterion, optimizer, opt)\n",
    "    time2 = time.time()\n",
    "    print('epoch {}, total time {:.2f}'.format(epoch, time2 - time1))\n",
    "\n",
    "    print(f'[Epoch{epoch}]train_acc', train_acc)\n",
    "    print('train_loss', train_loss)\n",
    "\n",
    "    test_acc, test_loss = validate(test_loader, model, criterion, opt)\n",
    "\n",
    "    print(f'[epoch {epoch}] test_acc : {test_acc}')\n",
    "    print(f'[epoch {epoch}] test_loss : {test_loss}')\n",
    "\n",
    "    # regular saving\n",
    "    if best_acc < test_acc :\n",
    "        best_acc = test_acc\n",
    "        print('==> Saving...')\n",
    "        save_file = os.path.join('./checkpoint/best.pth'.format(epoch=epoch))\n",
    "        torch.save(model.state_dict(), save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a829438-1e15-4932-9602-69ee17db1ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
